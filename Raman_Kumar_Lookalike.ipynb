{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID        CustomerName         Region  SignupDate\n",
      "0      C0001    Lawrence Carroll  South America  2022-07-10\n",
      "1      C0002      Elizabeth Lutz           Asia  2022-02-13\n",
      "2      C0003      Michael Rivera  South America  2024-03-07\n",
      "3      C0004  Kathleen Rodriguez  South America  2022-10-09\n",
      "4      C0005         Laura Weber           Asia  2022-08-15\n",
      "  ProductID              ProductName     Category   Price\n",
      "0      P001     ActiveWear Biography        Books  169.30\n",
      "1      P002    ActiveWear Smartwatch  Electronics  346.30\n",
      "2      P003  ComfortLiving Biography        Books   44.12\n",
      "3      P004            BookWorld Rug   Home Decor   95.69\n",
      "4      P005          TechPro T-Shirt     Clothing  429.31\n",
      "  TransactionID CustomerID ProductID      TransactionDate  Quantity  \\\n",
      "0        T00001      C0199      P067  2024-08-25 12:38:23         1   \n",
      "1        T00112      C0146      P067  2024-05-27 22:23:54         1   \n",
      "2        T00166      C0127      P067  2024-04-25 07:38:55         1   \n",
      "3        T00272      C0087      P067  2024-03-26 22:55:37         2   \n",
      "4        T00363      C0070      P067  2024-03-21 15:10:10         3   \n",
      "\n",
      "   TotalValue   Price  \n",
      "0      300.68  300.68  \n",
      "1      300.68  300.68  \n",
      "2      300.68  300.68  \n",
      "3      601.36  300.68  \n",
      "4      902.04  300.68  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load datasets\n",
    "customers = pd.read_csv('Customers.csv')\n",
    "products = pd.read_csv('Products.csv')\n",
    "transactions = pd.read_csv('Transactions.csv')\n",
    "\n",
    "# Inspect the first few rows of each dataset\n",
    "print(customers.head())\n",
    "print(products.head())\n",
    "print(transactions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge transactions with product data to get product category\n",
    "transactions = transactions.merge(products[['ProductID', 'Category']], on='ProductID')\n",
    "\n",
    "# Aggregate transaction data per customer\n",
    "customer_transactions = transactions.groupby(['CustomerID', 'Category']).agg(\n",
    "    total_spent=('TotalValue', 'sum'),\n",
    "    total_quantity=('Quantity', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Create a pivot table for customers with product categories as columns\n",
    "customer_profile = customer_transactions.pivot_table(\n",
    "    index='CustomerID',\n",
    "    columns='Category',\n",
    "    values='total_spent',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Include customer demographics (region, signup date) in the profile\n",
    "customer_profile = customer_profile.merge(customers[['CustomerID', 'Region']], on='CustomerID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize transaction data (numeric features only)\n",
    "scaler = StandardScaler()\n",
    "transaction_features = customer_profile.drop(['CustomerID', 'Region'], axis=1)\n",
    "transaction_features_scaled = pd.DataFrame(scaler.fit_transform(transaction_features), columns=transaction_features.columns)\n",
    "\n",
    "# Include the region (non-numeric) as it can also contribute to similarity\n",
    "customer_profile_scaled = pd.concat([customer_profile[['CustomerID', 'Region']], transaction_features_scaled], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerID     C0001     C0002     C0003     C0004     C0005     C0006  \\\n",
      "CustomerID                                                               \n",
      "C0001       1.000000 -0.402215  0.648350  0.043313  0.661203 -0.960708   \n",
      "C0002      -0.402215  1.000000  0.175482 -0.446094  0.257825  0.235584   \n",
      "C0003       0.648350  0.175482  1.000000  0.328565  0.932178 -0.734670   \n",
      "C0004       0.043313 -0.446094  0.328565  1.000000  0.092857 -0.005891   \n",
      "C0005       0.661203  0.257825  0.932178  0.092857  1.000000 -0.814067   \n",
      "\n",
      "CustomerID     C0007     C0008     C0009     C0010  ...     C0191     C0192  \\\n",
      "CustomerID                                          ...                       \n",
      "C0001       0.637812 -0.268011  0.171019 -0.381244  ... -0.059019  0.830892   \n",
      "C0002       0.166689  0.470266  0.588281  0.703980  ... -0.527737 -0.050379   \n",
      "C0003       0.996881  0.202597  0.198752 -0.372100  ... -0.448319  0.462407   \n",
      "C0004       0.347577  0.112209 -0.725347 -0.913367  ...  0.068221 -0.451726   \n",
      "C0005       0.945695 -0.065768  0.508871 -0.144782  ... -0.240979  0.657526   \n",
      "\n",
      "CustomerID     C0193     C0194     C0195     C0196     C0197     C0198  \\\n",
      "CustomerID                                                               \n",
      "C0001      -0.382490  0.576188 -0.030011 -0.719949  0.461473 -0.173126   \n",
      "C0002      -0.374197  0.036706  0.426021  0.311911  0.409603  0.762741   \n",
      "C0003      -0.605579  0.316061  0.610345 -0.146110  0.919496 -0.064460   \n",
      "C0004       0.104261 -0.379710  0.422922  0.433344  0.165504 -0.839495   \n",
      "C0005      -0.431373  0.220120  0.349060 -0.392847  0.967956  0.213940   \n",
      "\n",
      "CustomerID     C0199     C0200  \n",
      "CustomerID                      \n",
      "C0001       0.165667 -0.756913  \n",
      "C0002       0.522735  0.116516  \n",
      "C0003       0.840167 -0.867465  \n",
      "C0004       0.330655 -0.335804  \n",
      "C0005       0.817298 -0.918261  \n",
      "\n",
      "[5 rows x 199 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract the feature vectors (excluding CustomerID and Region)\n",
    "customer_vectors = customer_profile_scaled.drop(['CustomerID', 'Region'], axis=1)\n",
    "\n",
    "# Compute cosine similarity matrix\n",
    "similarity_matrix = cosine_similarity(customer_vectors)\n",
    "\n",
    "# Convert similarity matrix to a DataFrame for easier analysis\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=customer_profile_scaled['CustomerID'], columns=customer_profile_scaled['CustomerID'])\n",
    "\n",
    "# Inspect the similarity matrix\n",
    "print(similarity_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID LookalikeID  SimilarityScore\n",
      "0      C0001       C0091         0.988848\n",
      "1      C0001       C0069         0.984344\n",
      "2      C0001       C0184         0.978562\n",
      "3      C0002       C0159         0.979511\n",
      "4      C0002       C0036         0.956762\n"
     ]
    }
   ],
   "source": [
    "# Define the list of customers we are interested in (C0001 to C0020)\n",
    "target_customers = ['C0001', 'C0002', 'C0003', 'C0004', 'C0005', 'C0006', 'C0007', 'C0008', 'C0009', 'C0010',\n",
    "                    'C0011', 'C0012', 'C0013', 'C0014', 'C0015', 'C0016', 'C0017', 'C0018', 'C0019', 'C0020']\n",
    "\n",
    "# Create a dictionary to store the lookalike recommendations\n",
    "lookalike_map = defaultdict(list)\n",
    "\n",
    "# For each target customer, get top 3 similar customers (excluding themselves)\n",
    "for customer_id in target_customers:\n",
    "    similarities = similarity_df[customer_id].sort_values(ascending=False)  # Sort by similarity score\n",
    "    top_similar_customers = similarities.drop(customer_id).head(3)  # Exclude the customer itself\n",
    "    for similar_customer_id, score in top_similar_customers.items():\n",
    "        lookalike_map[customer_id].append((similar_customer_id, score))\n",
    "\n",
    "# Convert the lookalike map to a DataFrame\n",
    "lookalike_data = []\n",
    "for customer_id, similar_customers in lookalike_map.items():\n",
    "    for similar_customer_id, score in similar_customers:\n",
    "        lookalike_data.append([customer_id, similar_customer_id, score])\n",
    "\n",
    "lookalike_df = pd.DataFrame(lookalike_data, columns=['CustomerID', 'LookalikeID', 'SimilarityScore'])\n",
    "\n",
    "# Inspect the results\n",
    "print(lookalike_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the recommendations to a CSV file\n",
    "lookalike_df.to_csv('Raman_Kumar_Lookalike.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
